# AI-Powered Matching Engine

**Status:** âœ… COMPLETE (Core) | ðŸ“‹ PLANNED (Enhancements)

**Last Updated:** 2026-02-07

---

## Overview

The matching engine is TenderBot's core intelligence system. It combines deterministic filtering with LLM-powered refinement to deliver highly relevant tender opportunities to users based on their alert profiles.

### How It Works

1. **Candidate Selection** - Fast SQL query filters tenders by CPV codes, keywords, and regions
2. **LLM Refinement** - AI analyzes each candidate's relevance and generates summaries
3. **Confidence Scoring** - Only matches with >50% confidence are saved
4. **Deduplication** - Prevents duplicate matches across multiple runs

---

## User Value

- **Precision over noise** - AI filters out irrelevant tenders that match keywords superficially
- **Time savings** - 2-3 sentence summaries eliminate need to read full tender notices
- **Confidence transparency** - Users see why a tender matched their criteria
- **Continuous improvement** - Matching quality improves based on user feedback

---

## Technical Design

### Two-Stage Pipeline

```
Alert Profile â†’ Candidate Query â†’ LLM Refinement â†’ Confidence Filter â†’ Tender Matches
                      â†“                  â†“                  â†“
              (100-500 tenders)   (AI analysis)     (save if >0.5)
```

### Stage 1: Candidate Selection (Deterministic)

**SQL Query Logic:**

```sql
SELECT * FROM tenders t
WHERE
  -- CPV code overlap (GIN index)
  t.cpv_codes && %(alert_cpv_codes)s

  -- Keyword matching (full-text search on title + description)
  AND (
    t.title ILIKE ANY(%(keywords)s)
    OR t.description ILIKE ANY(%(keywords)s)
  )

  -- Region filtering (if specified)
  AND (%(regions)s IS NULL OR t.nuts_codes && %(regions)s)

  -- Only new tenders since last delivery
  AND t.publication_date > %(last_delivered_at)s

  -- Future deadline only
  AND t.bid_deadline > NOW()

ORDER BY t.publication_date DESC
LIMIT 500;
```

**Performance:**
- GIN index on `cpv_codes` enables fast array overlap: <50ms
- Full-text search on title/description: ~100ms
- Total query time: <200ms for 100K tender database

**Tuning Parameters:**
- `LIMIT 500` - Caps candidates per match run (prevents API timeouts)
- Keyword case-insensitive search: `ILIKE`
- CPV overlap operator: `&&` (array intersection)

### Stage 2: LLM Refinement (AI Analysis)

**Model:** OpenAI GPT-4o-mini (fast, cost-effective)

**Prompt Template:**

```
System: You are an expert public-sector tender analyst. Analyze the following tender
for relevance to the user's alert profile. Return JSON only.

User:
Alert Profile:
- Business Type: {business_type}
- CPV Categories: {cpv_codes}
- Keywords: {keywords}
- Regions: {regions}

Tender:
- Title: {tender.title}
- Description: {tender.description}
- CPV Codes: {tender.cpv_codes}
- Buyer: {tender.buyer_name} ({tender.buyer_type})
- Deadline: {tender.bid_deadline}
- Value: {tender.value_min_gbp} - {tender.value_max_gbp} GBP
- Region: {tender.nuts_codes}
- URL: {tender.tender_url}

Instructions:
1. Assess relevance based on business type, CPV match, keyword presence
2. Summarize in 1-2 sentences (max 200 chars)
3. Extract key details
4. Score confidence 0.0-1.0

Required JSON format:
{
  "tender_id": "{tender.id}",
  "title": "Short title",
  "summary": "One-sentence summary",
  "cpv_codes": ["72000000"],
  "keywords": ["keyword1", "keyword2"],
  "deadline": "YYYY-MM-DD",
  "estimated_value": 50000,
  "buyer_name": "Example Council",
  "buyer_type": "local-authority",
  "region": "South East",
  "confidence": 0.85
}
```

**Response Parsing:**
- Uses `response_format={"type": "json_object"}` for structured output
- Validates all required fields present
- Ensures `tender_id` matches input candidate (prevents hallucination)
- Confidence must be float between 0.0 and 1.0

**Batch Processing:**
- Processes 10 candidates per API call (reduces latency)
- Parallel requests with `asyncio.gather()`
- Total time for 100 candidates: ~8 seconds

**Error Handling:**
- Parse errors â†’ retry once, then skip candidate
- API rate limits â†’ exponential backoff
- Hallucinated tender_ids â†’ reject match, log warning
- Missing confidence â†’ default to 0.0 (rejected)

### Stage 3: Confidence Filtering & Persistence

**Threshold:** `confidence > 0.5`

**Database Insert:**

```sql
INSERT INTO tender_matches (
  id, alert_profile_id, tender_id, title, summary,
  cpv_codes, keywords, deadline, estimated_value,
  buyer_name, buyer_type, region, confidence, created_at
)
VALUES (...)
ON CONFLICT (alert_profile_id, tender_id) DO NOTHING;
```

**Deduplication:**
- Unique constraint on `(alert_profile_id, tender_id)`
- Prevents same tender from being matched multiple times
- Allows same tender to match different alert profiles

**Tracking Metrics:**
- `candidate_count` - SQL query results
- `refined_count` - Successful LLM analyses
- `persisted_count` - Matches saved (confidence > 0.5)
- `match_rate` = persisted / candidate (typically 20-40%)

---

## Matching Modes

### Exact Mode (Default)

**Use Case:** Regular alert deliveries

**Criteria:**
- CPV code overlap (at least 1 code matches)
- Keyword match (at least 1 keyword in title/description)
- Region match (if specified)
- Published since last delivery

**Precision:** High (~80% user satisfaction)
**Recall:** Medium (may miss some relevant tenders)

### Relaxed Mode (Preview)

**Use Case:** Onboarding preview, cold-start users

**Two-Tier Fallback:**

**Tier 1:**
- CPV overlap + NUTS region match
- No keyword requirement
- Sorted by publication date DESC
- Limit 5

**Tier 2 (if Tier 1 < 3 results):**
- CPV overlap only
- Ignore region
- Limit 5

**Precision:** Lower (~60% relevance)
**Recall:** Higher (shows more possibilities)

**Why Not Persist?**
- Too noisy for ongoing alerts
- Good for initial "what to expect" preview
- Users can refine keywords after seeing results

### Future: Hybrid Mode (PLANNED)

**Goal:** Balance precision and recall

**Approach:**
- Use LLM to generate expanded keyword list
- Semantic similarity search (embeddings)
- Learn from user actions (interested/dismiss feedback)

---

## CPV Code Matching

### CPV Hierarchy

CPV codes are 8-digit hierarchical codes:
- `72000000` - IT services (division)
- `72200000` - Software programming (group)
- `72220000` - Systems consultancy (class)

**Current Matching:** Exact code match only

**Limitation:** Misses parent/child relationships
- User selects `72220000` (systems consultancy)
- Tender has `72000000` (IT services - parent)
- No match occurs (even though tender is relevant)

**Enhancement (PLANNED):**
- Map user CPV codes to all parent codes
- Match if tender CPV is parent or child of user CPV
- Example: User `72220000` â†’ also match `72000000`, `72200000`

---

## Keyword Matching

### Current Implementation

**Search Strategy:**
- Case-insensitive substring match: `ILIKE '%keyword%'`
- Applied to: `title` + `description`
- OR logic: Any keyword match qualifies candidate

**Examples:**
- Keyword: "refurbishment"
- Matches: "Office Refurbishment Project", "Refurb of School Building"

**Stemming:** Not applied (PostgreSQL full-text search can be added)

**Phrase Matching:** Not supported (future enhancement)

### Keyword Suggestions (AI-Powered)

**Endpoint:** `POST /suggest/keywords`

**Input:**
```json
{
  "business_type": "electrical contractor",
  "categories": ["electrical", "construction"],
  "cpv_codes": ["45310000"]
}
```

**Output:**
```json
{
  "recommended_keywords": [
    "electrical installation",
    "wiring",
    "lighting",
    "power systems",
    "electrical maintenance"
  ],
  "confidence": 0.9
}
```

**Implementation:**
- Uses GPT-4o-mini with domain-specific prompt
- Trained to suggest UK public sector terminology
- Returns 5-10 keywords
- Fallback to static keyword list if API fails

---

## Confidence Scoring

### What Confidence Means

**0.0 - 0.3:** Likely irrelevant (not saved)
**0.3 - 0.5:** Possibly relevant (not saved, threshold too low)
**0.5 - 0.7:** Probably relevant (saved, shown in feed)
**0.7 - 0.9:** Highly relevant (saved, highlighted)
**0.9 - 1.0:** Perfect match (saved, top of feed)

### Factors Influencing Score

LLM considers:
1. **CPV code overlap** - How many codes match?
2. **Keyword density** - How many keywords appear?
3. **Business type alignment** - Does tender fit user's industry?
4. **Buyer type** - Does user typically work with this type of authority?
5. **Contract value** - Is it in user's typical range?
6. **Description clarity** - Is the tender well-described?

### Calibration

**Current Threshold:** 0.5 (balanced)

**User Feedback Loop (PLANNED):**
- Track "interested" vs "dismiss" actions
- If confidence > 0.8 but dismissed â†’ adjust threshold up
- If confidence 0.5-0.6 and interested â†’ adjust down
- Per-user calibration (future personalization)

---

## Performance & Costs

### Latency

**End-to-End Matching Time:**
- Candidate query: ~200ms
- LLM refinement (100 candidates): ~8 sec
- Database insert: ~50ms
- **Total: ~8.5 seconds**

**Alert Delivery Time:**
- Matching: 8.5 sec
- Email rendering: 0.5 sec
- Email send: 1 sec
- **Total: ~10 seconds**

### API Costs

**OpenAI GPT-4o-mini Pricing:**
- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens

**Typical Match Run:**
- 100 candidates
- ~500 tokens per candidate (input)
- ~150 tokens per response (output)
- Total: 50K input + 15K output tokens
- **Cost per match run: $0.017**

**Monthly Costs (1000 active users, daily alerts):**
- 30,000 match runs/month
- **~$510/month in API costs**

**Optimization Opportunities:**
- Cache match results (1-hour TTL)
- Batch users with similar profiles
- Use cheaper model for low-complexity matches

### Database Load

**Writes:**
- 30,000 match runs/month
- ~30 matches per run
- 900,000 `tender_matches` inserts/month

**Reads:**
- Dashboard: ~10 queries/user/day
- API endpoint: 300K requests/month

**Storage:**
- 900K matches Ã— 2KB avg = ~1.8GB/month
- Archive after 90 days: ~5.4GB steady state

---

## Success Metrics

**Match Quality:**
- 80%+ user satisfaction (interested / total shown)
- <10% dismiss rate
- >50% open rate on email alerts

**Performance:**
- <10 sec end-to-end matching
- 99.9% success rate (no errors)
- <$0.02 per match run

**Coverage:**
- >90% of relevant tenders surfaced
- <5% false positives (irrelevant matches)

---

## Future Enhancements

### 1. Semantic Search (Embeddings)

**Goal:** Match tenders based on meaning, not just keywords

**Approach:**
- Embed tender descriptions with `text-embedding-3-small`
- Embed user alert profile
- Cosine similarity search
- Combine with CPV filtering

**Benefit:** Find relevant tenders even without keyword overlap

### 2. User Feedback Loop

**Goal:** Learn from user actions to improve matching

**Data Collection:**
- Track "interested" and "dismiss" actions
- Store with confidence score and match features

**Model Training:**
- Fine-tune LLM prompt based on feedback
- Adjust confidence threshold per user
- Predict likelihood of interest

### 3. Multi-Criteria Scoring

**Goal:** More transparent, interpretable matching

**Dimensions:**
- Relevance (0-100): How well does it match profile?
- Competitiveness (0-100): How many competitors likely?
- Value (0-100): Is contract value in user's range?
- Urgency (0-100): How soon is the deadline?

**UI Display:** Show breakdown of each score

### 4. Alert Profile Templates

**Goal:** Faster onboarding with pre-built profiles

**Templates:**
- "Electrical Contractor"
- "IT Services Provider"
- "Construction Consultant"
- "Facilities Management"

**Each Template Includes:**
- Pre-selected CPV codes
- Recommended keywords
- Typical regions

---

## File Locations

**Backend:**
- Flow: `/backend/tenderbot/tasks/flows/matching_flow.py`
- Task: `/backend/tenderbot/tasks/generate_matches_task.py`
- Repository: `/backend/tenderbot/data/matching_repo.py`
- LLM Service: `/backend/tenderbot/services/openai_client.py`

---

## Dependencies

- OpenAI API (GPT-4o-mini)
- PostgreSQL with GIN indexes
- Prefect for orchestration
- `asyncio` for parallel processing

---

## References

- CPV Codes: https://simap.ted.europa.eu/web/simap/cpv
- OCDS Specification: https://standard.open-contracting.org/
- OpenAI JSON Mode: https://platform.openai.com/docs/guides/json-mode
